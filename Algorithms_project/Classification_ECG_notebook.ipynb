{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXVwchxOZMx2"
      },
      "source": [
        "# Electrocardiogram (ECG) classification using three different algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypQvHoHQZMx7"
      },
      "source": [
        "The objective is to classify (in a supervised way) the INCART 12-lead Arrhythmia Database, developed by the St. Petersburg Institute of Cardiological Technics, using three different models: $k$-Nearest Neighbors classifier, Random Forest algorithm and an Artificial Neural Network.\n",
        "\n",
        "The complete database is a comprehensive collection of ECG recordings aimed at supporting research in arrhythmia detection and analysis. This database consists of 75 annotated recordings derived from 32 Holter monitor records. Each recording is 30 minutes long and includes data from 12 standard ECG leads, sampled at 257 Hz. This dataset is publicly available through PhysioNet, a repository for medical research data managed by the MIT Laboratory for Computational Physiology, and is widely used for developing and testing algorithms for ECG analysis.\n",
        "\n",
        "The complete dataset contains 10 kinds of diagnoses beyond the recordings classified as normal. But in this paper only the normal and the irregular heartbeat are considered. For this reason the class labeled as 'N' (normal beat) is mapped into 1 and all the other labels into 0.\n",
        "\n",
        "For reducing the computations, only a subset of the entire dataset will be taken in accont: 10 recordings for each patient will be listed into a Pandas dataframe. The chosen attributes contain the measures of ECG peaks and intervals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X18_3vjOZMx9"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NprAhJasZMx-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "CcT0seUmZMyA",
        "outputId": "c62d3ba0-c4ef-482d-c6f0-a2216f388978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(750, 13)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    record type  0_pre-RR  0_post-RR   0_pPeak   0_tPeak   0_rPeak   0_sPeak  \\\n",
              "0      I01    N       163        165  0.069610 -0.083281  0.614133 -0.392761   \n",
              "1      I01    N       165        166 -0.097030  0.597254 -0.078704 -0.078704   \n",
              "2      I01    N       166        102  0.109399  0.680528 -0.010649 -0.010649   \n",
              "3      I01  VEB       102        231  0.176376  0.256431 -0.101098 -0.707525   \n",
              "4      I01    N       231        165  0.585577  0.607461 -0.083499 -0.083499   \n",
              "..     ...  ...       ...        ...       ...       ...       ...       ...   \n",
              "745    I75    N       210        205 -0.152757  0.766852 -0.177058 -0.177058   \n",
              "746    I75    N       205        206 -0.165687  0.778149 -0.488176 -0.488176   \n",
              "747    I75    N       206        207 -0.164147  0.809764 -0.636810 -0.636810   \n",
              "748    I75    N       207        148 -0.149094  0.867021 -0.419573 -0.419573   \n",
              "749    I75  VEB       148        262  0.196388  1.240515 -1.944161 -2.133533   \n",
              "\n",
              "      0_qPeak  0_qrs_interval  0_pq_interval  0_qt_interval  0_st_interval  \n",
              "0    0.047159              15              2             27             10  \n",
              "1   -0.137781               3              5             14              6  \n",
              "2   -0.720620               6             25             35              4  \n",
              "3   -0.101098               4              3             14              7  \n",
              "4   -0.167858               3             34             43              6  \n",
              "..        ...             ...            ...            ...            ...  \n",
              "745 -0.862051               3              9             16              4  \n",
              "746 -0.879209               2              9             16              5  \n",
              "747 -0.930783               2              9             16              5  \n",
              "748 -0.885266               3              9             16              4  \n",
              "749 -1.944161               2             41             57             14  \n",
              "\n",
              "[750 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9ef75fc-0cc4-4422-a1a9-3763a22b290c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>record</th>\n",
              "      <th>type</th>\n",
              "      <th>0_pre-RR</th>\n",
              "      <th>0_post-RR</th>\n",
              "      <th>0_pPeak</th>\n",
              "      <th>0_tPeak</th>\n",
              "      <th>0_rPeak</th>\n",
              "      <th>0_sPeak</th>\n",
              "      <th>0_qPeak</th>\n",
              "      <th>0_qrs_interval</th>\n",
              "      <th>0_pq_interval</th>\n",
              "      <th>0_qt_interval</th>\n",
              "      <th>0_st_interval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I01</td>\n",
              "      <td>N</td>\n",
              "      <td>163</td>\n",
              "      <td>165</td>\n",
              "      <td>0.069610</td>\n",
              "      <td>-0.083281</td>\n",
              "      <td>0.614133</td>\n",
              "      <td>-0.392761</td>\n",
              "      <td>0.047159</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I01</td>\n",
              "      <td>N</td>\n",
              "      <td>165</td>\n",
              "      <td>166</td>\n",
              "      <td>-0.097030</td>\n",
              "      <td>0.597254</td>\n",
              "      <td>-0.078704</td>\n",
              "      <td>-0.078704</td>\n",
              "      <td>-0.137781</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I01</td>\n",
              "      <td>N</td>\n",
              "      <td>166</td>\n",
              "      <td>102</td>\n",
              "      <td>0.109399</td>\n",
              "      <td>0.680528</td>\n",
              "      <td>-0.010649</td>\n",
              "      <td>-0.010649</td>\n",
              "      <td>-0.720620</td>\n",
              "      <td>6</td>\n",
              "      <td>25</td>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I01</td>\n",
              "      <td>VEB</td>\n",
              "      <td>102</td>\n",
              "      <td>231</td>\n",
              "      <td>0.176376</td>\n",
              "      <td>0.256431</td>\n",
              "      <td>-0.101098</td>\n",
              "      <td>-0.707525</td>\n",
              "      <td>-0.101098</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I01</td>\n",
              "      <td>N</td>\n",
              "      <td>231</td>\n",
              "      <td>165</td>\n",
              "      <td>0.585577</td>\n",
              "      <td>0.607461</td>\n",
              "      <td>-0.083499</td>\n",
              "      <td>-0.083499</td>\n",
              "      <td>-0.167858</td>\n",
              "      <td>3</td>\n",
              "      <td>34</td>\n",
              "      <td>43</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>I75</td>\n",
              "      <td>N</td>\n",
              "      <td>210</td>\n",
              "      <td>205</td>\n",
              "      <td>-0.152757</td>\n",
              "      <td>0.766852</td>\n",
              "      <td>-0.177058</td>\n",
              "      <td>-0.177058</td>\n",
              "      <td>-0.862051</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>I75</td>\n",
              "      <td>N</td>\n",
              "      <td>205</td>\n",
              "      <td>206</td>\n",
              "      <td>-0.165687</td>\n",
              "      <td>0.778149</td>\n",
              "      <td>-0.488176</td>\n",
              "      <td>-0.488176</td>\n",
              "      <td>-0.879209</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>I75</td>\n",
              "      <td>N</td>\n",
              "      <td>206</td>\n",
              "      <td>207</td>\n",
              "      <td>-0.164147</td>\n",
              "      <td>0.809764</td>\n",
              "      <td>-0.636810</td>\n",
              "      <td>-0.636810</td>\n",
              "      <td>-0.930783</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>I75</td>\n",
              "      <td>N</td>\n",
              "      <td>207</td>\n",
              "      <td>148</td>\n",
              "      <td>-0.149094</td>\n",
              "      <td>0.867021</td>\n",
              "      <td>-0.419573</td>\n",
              "      <td>-0.419573</td>\n",
              "      <td>-0.885266</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>I75</td>\n",
              "      <td>VEB</td>\n",
              "      <td>148</td>\n",
              "      <td>262</td>\n",
              "      <td>0.196388</td>\n",
              "      <td>1.240515</td>\n",
              "      <td>-1.944161</td>\n",
              "      <td>-2.133533</td>\n",
              "      <td>-1.944161</td>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>57</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>750 rows Ã— 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9ef75fc-0cc4-4422-a1a9-3763a22b290c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9ef75fc-0cc4-4422-a1a9-3763a22b290c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9ef75fc-0cc4-4422-a1a9-3763a22b290c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-989b0cb8-3d2e-4af3-8567-2fe0bdc05672\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-989b0cb8-3d2e-4af3-8567-2fe0bdc05672')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-989b0cb8-3d2e-4af3-8567-2fe0bdc05672 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 750,\n  \"fields\": [\n    {\n      \"column\": \"record\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          \"I05\",\n          \"I64\",\n          \"I11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"N\",\n          \"VEB\",\n          \"SVEB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_pre-RR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65,\n        \"min\": 49,\n        \"max\": 389,\n        \"num_unique_values\": 234,\n        \"samples\": [\n          210,\n          189,\n          262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_post-RR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 64,\n        \"min\": 96,\n        \"max\": 402,\n        \"num_unique_values\": 233,\n        \"samples\": [\n          285,\n          299,\n          105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_pPeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.209778981781365,\n        \"min\": -0.419846025,\n        \"max\": 1.816222522,\n        \"num_unique_values\": 750,\n        \"samples\": [\n          -0.012730923,\n          0.305716219,\n          -0.018181992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_tPeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6156651593070492,\n        \"min\": -2.114893059,\n        \"max\": 3.042195433,\n        \"num_unique_values\": 750,\n        \"samples\": [\n          -0.568421902,\n          -0.354928108,\n          -0.371338423\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_rPeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.826403997451721,\n        \"min\": -3.030707938,\n        \"max\": 2.894670431,\n        \"num_unique_values\": 750,\n        \"samples\": [\n          1.543636723,\n          2.068467581,\n          1.422273108\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_sPeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7842190848723607,\n        \"min\": -4.530016767,\n        \"max\": 2.894670431,\n        \"num_unique_values\": 750,\n        \"samples\": [\n          -1.008169625,\n          -1.140812803,\n          -0.582913726\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_qPeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35725539961706854,\n        \"min\": -3.030707938,\n        \"max\": 1.814054905,\n        \"num_unique_values\": 750,\n        \"samples\": [\n          -0.344906446,\n          -0.165621617,\n          -0.048863193\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_qrs_interval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 67,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          19,\n          40,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_pq_interval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 71,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          33,\n          36,\n          34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_qt_interval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 6,\n        \"max\": 136,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          6,\n          42,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0_st_interval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 1,\n        \"max\": 70,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          62,\n          50,\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df = pd.read_csv('incart_subset.csv')\n",
        "print(df.shape)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N69fnsgyZMyF"
      },
      "source": [
        "The target column is called 'type'. It will be separated from the feature columns and mapped into {0,1}."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvvNN8WvZMyG",
        "outputId": "c15d3c32-42c8-44a3-d3e0-38f896dcc19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of X is (750, 11) and the shape of y is (750,)\n"
          ]
        }
      ],
      "source": [
        "numeric_columns = [col for col in df.columns if '0_' in col]\n",
        "X = df[numeric_columns]\n",
        "y = df['type']\n",
        "print(f'The shape of X is {X.shape} and the shape of y is {y.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60_SgZOIZMyG",
        "outputId": "ca3de956-4b95-4cb3-c746-baba694239ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The class labels are ['N' 'VEB' 'SVEB']\n"
          ]
        }
      ],
      "source": [
        "class_labels = y.unique()\n",
        "print(f'The class labels are {class_labels}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx0pjX4vZMyH",
        "outputId": "4afc6e99-947f-4256-ec22-fa0d9c860e61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The class labels have become [1 0]\n"
          ]
        }
      ],
      "source": [
        "y = y.map({'N': 1, 'VEB': 0, 'SVEB':0})\n",
        "class_labels = y.unique()\n",
        "print(f'The class labels have become {class_labels}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8r9TwGdZMyI"
      },
      "source": [
        "Now, we must split the dataset in training and test sets. The training set is used to fit the data, while the test set is used to evaluate the model.\n",
        "\n",
        "Usually, when some medical data are studied, it is recommended that if one patient recording belongs to the test set, the other recordings of the same patient cannot be stored in the training set (and viceversa). It's for this reason that we do not choose randomly the rows of the dataset, but we choose randomply the 20% of the 75 patients to build the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsyqzRvNZMyK",
        "outputId": "9ab0c1a3-5379-4603-ba1a-c51777cfa67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 patients are in the test set\n",
            "The patients randomly chosen are ['I35', 'I59', 'I70', 'I25', 'I41', 'I30', 'I11', 'I22', 'I65', 'I36', 'I29', 'I31', 'I32', 'I14', 'I61']\n",
            "The length of the test dataset is 150\n"
          ]
        }
      ],
      "source": [
        "nr_test_patients = int(75 * 0.2)\n",
        "print(f'{nr_test_patients} patients are in the test set')\n",
        "\n",
        "random_records = random.sample(list(df['record'].unique()), k=nr_test_patients)\n",
        "print(f'The patients randomly chosen are {random_records}')\n",
        "\n",
        "test_indexes = []\n",
        "for r in random_records:\n",
        "    test_indexes  = test_indexes + list(df[df['record'] == r].index)\n",
        "print(f'The length of the test dataset is {len(test_indexes)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00INS8bIZMyK",
        "outputId": "b00d5eb3-bae0-4aa3-d9f5-3436bfb37c6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of X_test is (150, 11), shape of y_test is (150,)\n",
            "shape of X_train is (600, 11), shape of y_train is (600,)\n"
          ]
        }
      ],
      "source": [
        "X_test = X.loc[test_indexes]\n",
        "y_test = y[test_indexes]\n",
        "\n",
        "train_indexes = list(set(X.index) - set(X_test.index))\n",
        "X_train  = X.loc[train_indexes]\n",
        "y_train  = y[train_indexes]\n",
        "\n",
        "print(f'shape of X_test is {X_test.shape}, shape of y_test is {y_test.shape}')\n",
        "print(f'shape of X_train is {X_train.shape}, shape of y_train is {y_train.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0n-xSqPZMyL"
      },
      "source": [
        "Since the following algorithms are implemented supposing that inputs are NumPy array, then we transform training and test sets. NumPy arrays are very suitable for a big amount of numerical computations. They are optimized for performance, and so they are significantly fast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2LSzuoaZMyL",
        "outputId": "bb9a6163-c3d0-4fe7-bcd8-8e5ef0c02411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The type of X_test is <class 'numpy.ndarray'>\n",
            "The type of y_test is <class 'numpy.ndarray'>\n",
            "The type of X_train is <class 'numpy.ndarray'>\n",
            "The type of y_train is <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "\n",
        "X_train  = X_train.values\n",
        "y_train  = y_train.values\n",
        "\n",
        "print(f'The type of X_test is {type(X_test)}\\nThe type of y_test is {type(y_test)}\\nThe type of X_train is {type(X_train)}\\nThe type of y_train is {type(y_train)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfo-HQgiZMyM"
      },
      "source": [
        "# Accuracy function\n",
        "\n",
        "For understanding if the classifier predicts well the labels, we can sum the number of time in which class label predicted is equal to the true value. It's for this reason that the accuracy function is implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "46cqKoNaZMyM"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_test, y_pred):\n",
        "    sum_correct = sum([pred==test for pred,test in zip(y_pred,y_test)])\n",
        "    acc = sum_correct/len(y_test)\n",
        "    nr_errors = y_test.shape[0] - sum_correct\n",
        "    print(f'The number of errors is {nr_errors} out of {y_test.shape[0]}')\n",
        "    print(f'The model has an accuracy of {round(acc * 100, 2)} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6cga-QBZMyM"
      },
      "source": [
        "# $k$-Nearest Neighbors (kNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jd0ttvVgZMyN"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    '''\n",
        "    Class which implements the k nearest neighbors classifier.\n",
        "    '''\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Function used to train a decision tree classifier model.\n",
        "\n",
        "        :param X: np.array, features\n",
        "        :param y: np.array or list, target\n",
        "        :return: None\n",
        "        '''\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        y_pred = []\n",
        "        for x in X_test:\n",
        "            # Calculate the distances between x and all training points\n",
        "            distances = np.linalg.norm(self.X - x, axis=1)\n",
        "            # Sort training point indices by distance\n",
        "            sorted_indices = np.argsort(distances)\n",
        "            # Get the k nearest neighbors\n",
        "            k_indices = sorted_indices[:self.k]\n",
        "            # Get the matching labels\n",
        "            k_labels = self.y[k_indices]\n",
        "            # Predict the most common label\n",
        "            unique_labels, counts = np.unique(k_labels, return_counts=True)\n",
        "            most_common_label = unique_labels[np.argmax(counts)]\n",
        "            y_pred.append(most_common_label)\n",
        "        return np.array(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbz4qXSyZMyN",
        "outputId": "f1d845cf-ef97-4c47-bc06-c173d49ffe28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of errors is 10 out of 150\n",
            "The model has an accuracy of 93.33 %\n"
          ]
        }
      ],
      "source": [
        "knn = KNN(k=3)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uaTgeoaZMyO"
      },
      "source": [
        "# Random Forest algorithm\n",
        "\n",
        "First of all a decision tree must be implemented. Then we can build the Radom Forest algorithm with a bootstrap sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2LmSyPXhZMyO"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    '''\n",
        "    Helper class which implements a single tree node.\n",
        "    '''\n",
        "    def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gain=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.data_left = data_left\n",
        "        self.data_right = data_right\n",
        "        self.gain = gain\n",
        "        self.value = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tbplVLDcZMyP"
      },
      "outputs": [],
      "source": [
        "class DecisionTree:\n",
        "    '''\n",
        "    Class which implements a decision tree classifier algorithm.\n",
        "    '''\n",
        "    def __init__(self, min_samples_split=2, max_depth=5):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.root = None\n",
        "\n",
        "    @ staticmethod # Static methods do not receive any implicit first argument. This means they do not have access to the instance (self) or the class\n",
        "    def _gini_index(s):\n",
        "        '''\n",
        "        Helper function, calculates gini index from an array of integer values.\n",
        "\n",
        "        :param s: list\n",
        "        :return: float, gini index value\n",
        "        '''\n",
        "        # Convert to integers to avoid runtime errors\n",
        "        # bincount returns the count of values in each bin from 0 to the largest value in the array\n",
        "        counts = np.bincount(np.array(s, dtype=np.int64))\n",
        "        # Probabilities of each class label\n",
        "        percentages = counts / len(s)\n",
        "\n",
        "        # Caclulate entropy\n",
        "        gini = 1\n",
        "        for pct in percentages:\n",
        "            if pct > 0:\n",
        "                gini -= pct ** 2\n",
        "        return gini\n",
        "\n",
        "\n",
        "    def _information_gain(self, parent, left_child, right_child):\n",
        "        '''\n",
        "        Helper function, calculates information gain from a parent and two child nodes.\n",
        "\n",
        "        :param parent: list, the parent node\n",
        "        :param left_child: list, left child of a parent\n",
        "        :param right_child: list, right child of a parent\n",
        "        :return: float, information gain\n",
        "        '''\n",
        "        # Compute n_k /n, for k = 1,2 where n_1 is the number of samples in left child, n_2 is the number of samples in right child, n is the number of samples in parent node\n",
        "        num_left = len(left_child) / len(parent)\n",
        "        num_right = len(right_child) / len(parent)\n",
        "\n",
        "        # One-liner which implements the previously discussed formula\n",
        "        return self._gini_index(parent) - (num_left * self._gini_index(left_child) + num_right * self._gini_index(right_child))\n",
        "\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        '''\n",
        "        Helper function, calculates the best split for given features and target\n",
        "\n",
        "        :param X: np.array, features\n",
        "        :param y: np.array or list, target\n",
        "        :return: dict\n",
        "        '''\n",
        "        best_split = None\n",
        "        best_info_gain = -1\n",
        "        n_rows, n_cols = X.shape\n",
        "\n",
        "        # For every dataset feature\n",
        "        for f_idx in range(n_cols):\n",
        "            X_curr = X[:, f_idx]\n",
        "            # For every unique value of that feature\n",
        "            for threshold in np.unique(X_curr):\n",
        "                # Construct a dataset and split it to the left and right parts\n",
        "                # Left part includes records lower or equal to the threshold\n",
        "                # Right part includes records higher than the threshold\n",
        "                df = np.concatenate((X, y.reshape(1, -1).T), axis=1)\n",
        "                df_left = np.array([row for row in df if row[f_idx] <= threshold])\n",
        "                df_right = np.array([row for row in df if row[f_idx] > threshold])\n",
        "\n",
        "                # Do the calculation only if there's data in both subsets\n",
        "                if len(df_left) > 0 and len(df_right) > 0:\n",
        "                    # Obtain the value of the target variable for subsets\n",
        "                    y = df[:, -1]\n",
        "                    y_left = df_left[:, -1]\n",
        "                    y_right = df_right[:, -1]\n",
        "\n",
        "                    # Caclulate the information gain and save the split parameters\n",
        "                    # if the current split is better then the previous best\n",
        "                    gain = self._information_gain(y, y_left, y_right)\n",
        "                    if gain > best_info_gain:\n",
        "                        best_split = {\n",
        "                            'feature_index': f_idx,\n",
        "                            'threshold': threshold,\n",
        "                            'df_left': df_left,\n",
        "                            'df_right': df_right,\n",
        "                            'gain': gain\n",
        "                        }\n",
        "                        best_info_gain = gain\n",
        "        return best_split\n",
        "\n",
        "    def _build(self, X, y, depth=0):\n",
        "        '''\n",
        "        Helper recursive function, used to build a decision tree from the input data.\n",
        "\n",
        "        :param X: np.array, features\n",
        "        :param y: np.array or list, target\n",
        "        :param depth: current depth of a tree, used as a stopping criteria\n",
        "        :return: Node\n",
        "        '''\n",
        "        n_rows, n_cols = X.shape\n",
        "\n",
        "        # Check to see if a node should be leaf node\n",
        "        if n_rows >= self.min_samples_split and depth <= self.max_depth:\n",
        "            # Get the best split\n",
        "            best = self._best_split(X, y)\n",
        "            # If the split isn't pure\n",
        "            if best and best['gain'] > 0:\n",
        "                # Build a tree on the left\n",
        "                left = self._build(\n",
        "                    X=best['df_left'][:, :-1],\n",
        "                    y=best['df_left'][:, -1],\n",
        "                    depth=depth + 1\n",
        "                )\n",
        "                right = self._build(\n",
        "                    X=best['df_right'][:, :-1],\n",
        "                    y=best['df_right'][:, -1],\n",
        "                    depth=depth + 1\n",
        "                )\n",
        "                return Node(\n",
        "                    feature=best['feature_index'],\n",
        "                    threshold=best['threshold'],\n",
        "                    data_left=left,\n",
        "                    data_right=right,\n",
        "                    gain=best['gain']\n",
        "                )\n",
        "        # Leaf node value is the most common target value\n",
        "        return Node(\n",
        "            value=Counter(y).most_common(1)[0][0]\n",
        "        )\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Function used to train a decision tree classifier model.\n",
        "\n",
        "        :param X: np.array, features\n",
        "        :param y: np.array or list, target\n",
        "        :return: None\n",
        "        '''\n",
        "        # Call a recursive function to build the tree\n",
        "        self.root = self._build(X, y)\n",
        "\n",
        "    def _predict(self, x, tree):\n",
        "        '''\n",
        "        Helper recursive function, used to predict a single instance (tree traversal).\n",
        "\n",
        "        :param x: single observation\n",
        "        :param tree: built tree\n",
        "        :return: float, predicted class\n",
        "        '''\n",
        "        # Leaf node\n",
        "        if tree.value is not None:\n",
        "            return tree.value\n",
        "\n",
        "        feature_value = x[tree.feature]\n",
        "\n",
        "        # Go to the left\n",
        "        if feature_value <= tree.threshold:\n",
        "            return self._predict(x=x, tree=tree.data_left)\n",
        "\n",
        "        # Go to the right\n",
        "        if feature_value > tree.threshold:\n",
        "            return self._predict(x=x, tree=tree.data_right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Function used to classify new instances.\n",
        "\n",
        "        :param X: np.array, features\n",
        "        :return: np.array, predicted classes\n",
        "        '''\n",
        "        # Call the _predict() function for every observation\n",
        "        return [self._predict(x, self.root) for x in X]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjnujif9ZMyP",
        "outputId": "0c57cad6-408b-4ec0-9ed0-f39f2ee86f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of errors is 13 out of 150\n",
            "The model has an accuracy of 91.33 %\n"
          ]
        }
      ],
      "source": [
        "dt_model = DecisionTree()\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "accuracy(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QgCV-8E9ZMyQ"
      },
      "outputs": [],
      "source": [
        "class RandomForest:\n",
        "    '''\n",
        "    Class which implements random forest algorithm.\n",
        "    '''\n",
        "    def __init__(self, n_estimators=5, min_samples_split=2, max_depth=5, n_features=5):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.n_features = n_features\n",
        "        self.trees = []\n",
        "\n",
        "    def _bootstrap_sample(self, X, y):\n",
        "        '''\n",
        "        Helper function, used to generate bootstrap samples.\n",
        "\n",
        "        :param X: np.array, features\n",
        "        :param y: np.array or list, target\n",
        "        :return: two np.array, features and target sampled by bootstrap method\n",
        "        '''\n",
        "        n_samples = X.shape[0]\n",
        "        # Choose randomly (with repetition) the indexes of examples from the original dataset\n",
        "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        return X[indices], y[indices]\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Function used to train a random forest.\n",
        "\n",
        "        :param X: np.array, features\n",
        "        :param y: np.array or list, target\n",
        "        :return: None\n",
        "        '''\n",
        "        for _ in range(self.n_estimators):\n",
        "            tree = DecisionTree(min_samples_split=self.min_samples_split, max_depth=self.max_depth)\n",
        "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
        "            # Choose randomly n_features\n",
        "            random_features = [0,1] + random.sample(range(2,X.shape[1]), self.n_features)\n",
        "            print(f'features of the {_+1} decision tree are {random_features}')\n",
        "            # Fit the decision tree on the dataset with a reduced number of columns\n",
        "            tree.fit(X_sample[:,random_features], y_sample)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Function used to classify new instances.\n",
        "\n",
        "        :param X: np.array, features\n",
        "        :return: np.array, predicted classes\n",
        "        '''\n",
        "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
        "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
        "        y_pred = [Counter(tree_pred).most_common(1)[0][0] for tree_pred in tree_preds]\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6c1DDg4ZMyR"
      },
      "source": [
        "Because of the randomicity in the choice of features subset, we run the algorithm more the one time to visualize possible changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXE368XnZMyR",
        "outputId": "f7cd6835-65a2-45c6-ec24-74074d21c46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The index 0 is related to the name column 0_pre-RR\n",
            "The index 1 is related to the name column 0_post-RR\n",
            "The index 2 is related to the name column 0_pPeak\n",
            "The index 3 is related to the name column 0_tPeak\n",
            "The index 4 is related to the name column 0_rPeak\n",
            "The index 5 is related to the name column 0_sPeak\n",
            "The index 6 is related to the name column 0_qPeak\n",
            "The index 7 is related to the name column 0_qrs_interval\n",
            "The index 8 is related to the name column 0_pq_interval\n",
            "The index 9 is related to the name column 0_qt_interval\n",
            "The index 10 is related to the name column 0_st_interval\n"
          ]
        }
      ],
      "source": [
        "col_names = X.columns\n",
        "for i, feature in enumerate(col_names):\n",
        "    print(f'The index {i} is related to the name column {feature}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inKTkN1zZMyR",
        "outputId": "67bd3cd5-3490-4483-ac46-232a5d018521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features of the 1 decision tree are [0, 1, 7, 5]\n",
            "features of the 2 decision tree are [0, 1, 3, 10]\n",
            "features of the 3 decision tree are [0, 1, 6, 3]\n",
            "The number of errors is 15 out of 150\n",
            "The model has an accuracy of 90.0 %\n",
            "features of the 1 decision tree are [0, 1, 8, 5]\n",
            "features of the 2 decision tree are [0, 1, 10, 3]\n",
            "features of the 3 decision tree are [0, 1, 5, 4]\n",
            "The number of errors is 13 out of 150\n",
            "The model has an accuracy of 91.33 %\n",
            "features of the 1 decision tree are [0, 1, 6, 5]\n",
            "features of the 2 decision tree are [0, 1, 7, 2]\n",
            "features of the 3 decision tree are [0, 1, 2, 3]\n",
            "The number of errors is 3 out of 150\n",
            "The model has an accuracy of 98.0 %\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "    rf_model = RandomForest(n_estimators=3, n_features=2, max_depth=4)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BsaI_ZMZMyS"
      },
      "source": [
        "After many trials, it was observed that to fit data mantaining the first and the second columns, the accuracy is never under 70%. The other columns are chosen randomly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmIUKVQZZMyT"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYNPFu7JZMyT"
      },
      "source": [
        "## Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "noO-OieIZMyU"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "        '''\n",
        "        Helper function, used to compute ReLU.\n",
        "\n",
        "        :param x: float or np.array or list\n",
        "        :return: float in (0,+inf)\n",
        "        '''\n",
        "        if (type(x) != float) & (type(x) != int):\n",
        "            return np.array([max(0,z) for z in x])\n",
        "        return max(0,x)\n",
        "\n",
        "\n",
        "def relu_derivative(x):\n",
        "    '''\n",
        "    Helper function, used to compute derivative of ReLU.\n",
        "\n",
        "    :param x: float or np.array or list\n",
        "    :return: float in (0,+inf)\n",
        "    '''\n",
        "    if (type(x) != float) & (type(x) != int):\n",
        "        der = []\n",
        "        for z in x:\n",
        "            if z > 0:\n",
        "                der.append(1)\n",
        "            else:\n",
        "                der.append(0)\n",
        "    else:\n",
        "        if x > 0:\n",
        "            der = 1\n",
        "        else:\n",
        "            der = 0\n",
        "    return der\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    '''\n",
        "    Helper function, used to compute sigmoid.\n",
        "\n",
        "    :param x: float\n",
        "    :return: float in (0,1)\n",
        "    '''\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    '''\n",
        "    Helper function, used to compute sigmoid derivative.\n",
        "\n",
        "    :param x: float\n",
        "    :return: float\n",
        "    '''\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "\n",
        "\n",
        "def cross_entropy(y_true, y_pred):\n",
        "    '''\n",
        "    Helper function, used to compute cross entropy.\n",
        "\n",
        "    :param y_true: bool, target\n",
        "    :param y_pred: float, probability in (0,1)\n",
        "    :return: float\n",
        "    '''\n",
        "    if y_true == y_pred:\n",
        "        return 0\n",
        "    # To avoid predictions 0 or 1\n",
        "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "    return - (y_true * np.log(y_pred)) - ((1-y_true) * np.log(1-y_pred))\n",
        "\n",
        "\n",
        "def cross_entropy_derivative(y_true, y_pred):\n",
        "    '''\n",
        "    Helper function, used to compute derivative of cross entropy.\n",
        "\n",
        "    :param y_true: bool, target\n",
        "    :param y_pred: float, probability in (0,1)\n",
        "    :return: float\n",
        "    '''\n",
        "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "    return (y_pred -y_true) / (y_pred * (1-y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHHoFREEZMyV"
      },
      "source": [
        "## Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_N8bzwxgZMyV"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    '''\n",
        "    Class which implements an artificial neural network.\n",
        "    '''\n",
        "    def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.01):\n",
        "        '''\n",
        "        Initialization of weights and biases.\n",
        "\n",
        "        :param input_size: int, number of input layer nodes\n",
        "        :param hidden_sizes: list, number of nodes for each hidden layer\n",
        "        :param output_size: int, number of out layer nodes\n",
        "        :param learning_rate: float, default learning rate is 0.01\n",
        "        :return: None\n",
        "        '''\n",
        "        self.input_size = input_size\n",
        "        self.hidden_sizes = hidden_sizes\n",
        "        self.output_size = output_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.Z = []\n",
        "        self.A = []\n",
        "        self.predictions = []\n",
        "\n",
        "        if len(self.hidden_sizes) == 1:\n",
        "            # Initialization of weights\n",
        "            np.random.seed(42)\n",
        "            self.weights_input_hidden = np.random.uniform(-1, 1, (self.input_size, self.hidden_sizes[0]))\n",
        "            self.weights_hidden_output = np.random.uniform(-1, 1, (self.hidden_sizes[0], self.output_size))\n",
        "            # Initialization of biases\n",
        "            self.bias_hidden = np.zeros(self.hidden_sizes[0])\n",
        "            self.bias_output = np.zeros(self.output_size)\n",
        "\n",
        "        else:\n",
        "            # Initialization of weights\n",
        "            np.random.seed(42)\n",
        "            self.weights_input_hidden = np.random.uniform(-1, 1, (self.input_size, self.hidden_sizes[0]))\n",
        "            self.weights_hidden_hidden = [np.random.uniform(-1, 1, (self.hidden_sizes[i], self.hidden_sizes[i+1])) for i in range(len(self.hidden_sizes)-1)]\n",
        "            if self.output_size == 1:\n",
        "                self.weights_hidden_output = np.random.uniform(-1, 1, self.hidden_sizes[-1])\n",
        "            else:\n",
        "                self.weights_hidden_output = np.random.uniform(-1, 1, (self.hidden_sizes[-1], self.output_size))\n",
        "            # Initialization of biases\n",
        "            self.bias_hidden = []\n",
        "            for hid in self.hidden_sizes:\n",
        "                self.bias_hidden.append(np.zeros(hid))\n",
        "            self.bias_output = np.zeros(self.output_size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _forward_pass(self, X):\n",
        "        '''\n",
        "        Helper function, used to do the forward pass.\n",
        "\n",
        "        :param X: np.array, features\n",
        "        :return: np.array, predicted probabilities\n",
        "        '''\n",
        "        # Initialization of output of hidden layes (z) and activations (a)\n",
        "        self.Z = []\n",
        "        self.A = []\n",
        "        # Initialization of predictions\n",
        "        self.predictions = []\n",
        "\n",
        "        for i,x in enumerate(X):\n",
        "            z = []\n",
        "            a = []\n",
        "\n",
        "            if len(self.hidden_sizes) == 1:\n",
        "                # Calculation of hidden and output layers outputs\n",
        "                z.append(np.dot(x, self.weights_input_hidden) + self.bias_hidden)\n",
        "                a.append(relu(z[-1]))\n",
        "\n",
        "                z.append(np.dot(a[-1], self.weights_hidden_output) + self.bias_output)\n",
        "                a.append(sigmoid(z[-1]))\n",
        "\n",
        "\n",
        "            else:\n",
        "                z.append(np.dot(x, self.weights_input_hidden) + self.bias_hidden[0])\n",
        "                a.append(relu(z[-1]))\n",
        "\n",
        "                for layer in range(len(self.hidden_sizes)-1):\n",
        "                    z.append(np.dot(a[-1], self.weights_hidden_hidden[layer]) + self.bias_hidden[layer+1])\n",
        "                    a.append(relu(z[-1]))\n",
        "\n",
        "                z.append(np.dot(a[-1], self.weights_hidden_output) + self.bias_output)\n",
        "                a.append(sigmoid(z[-1]))\n",
        "\n",
        "            self.Z.append(z)\n",
        "            self.A.append(a)\n",
        "            self.predictions.append(a[-1])\n",
        "        return np.array(self.predictions)\n",
        "\n",
        "\n",
        "\n",
        "    def _delta(self, y):\n",
        "        '''\n",
        "        Helper function, useed for computing the partial derivative of loss wrt the activation\n",
        "\n",
        "        '''\n",
        "        self.delta = []\n",
        "        for index,y_true in enumerate(y):\n",
        "            # L is the sum of hidden and output layers\n",
        "            L = len(self.hidden_sizes) + 1\n",
        "\n",
        "            # Initialization of delta\n",
        "            d = [np.zeros(self.hidden_sizes[0])]\n",
        "            if len(self.hidden_sizes) > 1:\n",
        "                for s in (self.hidden_sizes[1:]):\n",
        "                    d.append(np.zeros(s))\n",
        "            d.append(np.zeros(self.output_size))\n",
        "\n",
        "            # delta output [L-1]\n",
        "            d[L-1] = (cross_entropy_derivative(y_true, self.A[index][L-1][0]))\n",
        "\n",
        "            # delta hidden [L-2]\n",
        "            d[L-2] = d[L-1] * sigmoid_derivative(self.Z[index][L-1][0]) * self.weights_hidden_output\n",
        "\n",
        "\n",
        "            if L >= 3:\n",
        "                # delta hidden [L-3,...,0]:\n",
        "                for l in range(L-3, -1, -1):\n",
        "                    for j in range(len(self.weights_hidden_hidden[l])):\n",
        "                        d[l][j] = np.sum(list(d[l+1] * np.array(relu_derivative(self.Z[index][l+1])) * self.weights_hidden_hidden[l][j]))\n",
        "\n",
        "            self.delta.append(d)\n",
        "\n",
        "\n",
        "        return self.delta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _backward_pass(self, X, y):\n",
        "        '''\n",
        "        Helper function, used to perform the backward pass.\n",
        "\n",
        "        :param X: np.array, features\n",
        "        :param y: np.array, target\n",
        "        :return: np.array, predicted probabilities\n",
        "        '''\n",
        "        sum_der_w = [np.zeros((self.input_size, self.hidden_sizes[0]))]\n",
        "        if len(self.hidden_sizes) > 1:\n",
        "            for s in range(len(self.hidden_sizes)-1):\n",
        "                sum_der_w.append(np.zeros((self.hidden_sizes[s],self.hidden_sizes[s+1])))\n",
        "        sum_der_w.append(np.zeros((self.hidden_sizes[-1], self.output_size)))\n",
        "        sum_der_w = np.array(sum_der_w, dtype=object)\n",
        "\n",
        "        sum_der_b = []\n",
        "        for s in (self.hidden_sizes):\n",
        "            sum_der_b.append(np.zeros(s))\n",
        "        sum_der_b.append(np.zeros(self.output_size))\n",
        "        sum_der_b = np.array(sum_der_b, dtype=object)\n",
        "\n",
        "        for n,x in enumerate(X):\n",
        "            L = len(self.hidden_sizes)\n",
        "\n",
        "            # Partial derivatives of a wrt to z\n",
        "            der_a_z = []\n",
        "            for l in range(len(self.hidden_sizes)):\n",
        "                der_a_z.append(np.array(relu_derivative(self.Z[n][l])))\n",
        "            der_a_z.append(sigmoid_derivative(self.Z[n][L]))\n",
        "\n",
        "            # Partial derivative of C wrt w\n",
        "            der_C_w = []\n",
        "            der_C_w.append(np.array([self.delta[n][0].flatten() * der_a_z[0] * xj for xj in x]))\n",
        "\n",
        "            if L > 1:\n",
        "                for l in range(1,L):\n",
        "                    der_C_w.append(np.array([self.delta[n][l].flatten() * der_a_z[l] * aj  for aj in self.A[n][l-1]]))\n",
        "\n",
        "            der_C_w.append(np.array([self.delta[n][L].flatten() * der_a_z[L] * aj  for aj in self.A[n][-2]]))\n",
        "            der_C_w = np.array(der_C_w, dtype=object)\n",
        "\n",
        "            sum_der_w = sum_der_w + der_C_w\n",
        "\n",
        "            # Partial derivatives of C wrt b\n",
        "            der_C_b = []\n",
        "\n",
        "\n",
        "            for l in range(0,L):\n",
        "                der_C_b.append(self.delta[n][l] * der_a_z[l])\n",
        "\n",
        "            der_C_b.append(self.delta[n][L] * der_a_z[L] )\n",
        "            der_C_b = np.array(der_C_b, dtype=object)\n",
        "\n",
        "\n",
        "            # Addition of derivatives\n",
        "            sum_der_b = sum_der_b + der_C_b\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Update of weights\n",
        "        self.weights_input_hidden -= self.learning_rate * sum_der_w[0]\n",
        "        for hid in range(len(self.hidden_sizes)-1):\n",
        "            self.weights_hidden_hidden[hid] -= self.learning_rate * sum_der_w[hid+1]\n",
        "        if len(self.hidden_sizes) > 1:\n",
        "          self.weights_hidden_output -= self.learning_rate * sum_der_w[-1].flatten()\n",
        "        else:\n",
        "          self.weights_hidden_output -= self.learning_rate * sum_der_w[-1]\n",
        "\n",
        "\n",
        "        # Update of bias\n",
        "        for hid in range(len(self.hidden_sizes)-1):\n",
        "            self.bias_hidden[hid] -= self.learning_rate * sum_der_b[hid]\n",
        "        self.bias_output -= self.learning_rate * sum_der_b[-1]\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X, y, epochs=1000):\n",
        "        for epoch in range(epochs):\n",
        "            self._forward_pass(X)\n",
        "            self._delta(y)\n",
        "            self._backward_pass(X, y)\n",
        "\n",
        "            # Calculation of cross entropy\n",
        "            loss = np.zeros(X.shape[0])\n",
        "            for i,y_true,y_pred in zip(range(X.shape[0]), y, self.predictions):\n",
        "                loss[i] = cross_entropy(y_true, y_pred)\n",
        "            print(f'Epoch {epoch}, Loss: {np.mean(loss)}')\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self._forward_pass(X)\n",
        "        y_pred = []\n",
        "        for o in output:\n",
        "            if o > 0.5:\n",
        "                y_pred.append(1)\n",
        "            else:\n",
        "                y_pred.append(0)\n",
        "\n",
        "        return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzusx3rUZMyW",
        "outputId": "dc4d6211-4fd1-4ff7-b1d1-08d7199bc2d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-4e678c35ffdd>:224: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  loss[i] = cross_entropy(y_true, y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 28.4903144980968\n",
            "Epoch 1, Loss: 0.6142097063932765\n",
            "Epoch 2, Loss: 0.5550810312717986\n",
            "Epoch 3, Loss: 0.5118500806425518\n",
            "Epoch 4, Loss: 0.47983780947032934\n",
            "Epoch 5, Loss: 0.45579795019715497\n",
            "Epoch 6, Loss: 0.4374915596018487\n",
            "Epoch 7, Loss: 0.42336654317100275\n",
            "Epoch 8, Loss: 0.41233528722177243\n",
            "Epoch 9, Loss: 0.40362538562929334\n",
            "Epoch 10, Loss: 0.3966804007752502\n",
            "Epoch 11, Loss: 0.39109373691203475\n",
            "Epoch 12, Loss: 0.3865642005603818\n",
            "Epoch 13, Loss: 0.38286578509906294\n",
            "Epoch 14, Loss: 0.37982685613823153\n",
            "The number of errors is 21 out of 150\n",
            "The model has an accuracy of 86.0 %\n"
          ]
        }
      ],
      "source": [
        "nn_model = NeuralNetwork(input_size=11, hidden_sizes=[2,3,4], output_size=1, learning_rate=0.001)\n",
        "nn_model.fit(X_train, y_train, epochs=15)\n",
        "y_pred = nn_model.predict(X_test)\n",
        "accuracy(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}